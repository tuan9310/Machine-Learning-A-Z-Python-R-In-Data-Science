{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing_tools.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuan9310/Machine-Learning-Data-Science-Python-/blob/main/data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "yLgFVvYdYLsB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aBHnWOfoHPrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function:**\n",
        "*   read_csv('File_name'): Read csv file\n",
        "*   iloc[row, column].values: interger position based (from 0 to lenghth -1 of the axis)\n",
        "    \n",
        "    Paramater: ':' is range, ':-1' is range from \n",
        "the beginning to the second from last column.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FOh08afjGOt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a dataframe (2D Array)\n",
        "dataset = pd.read_csv('Data.csv')\n",
        "\n",
        "# Check the data type of object dataset\n",
        "print(type(dataset))\n",
        "\n",
        "# Get all the independent variables. iloc[:, :-1].values get values of all rows, from the first column to the second to last column\n",
        "x = dataset.iloc[:, :-1].values\n",
        "\n",
        "# Get the dependent variable, which is locate at the last column. \n",
        "y = dataset.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "t9kb7y-TYgcG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723fb03d-b40f-42a7-eb01-bf1d7f71e785"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hdDlQkzvmqXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IuBMkotavD1",
        "outputId": "209ff8af-13f6-4a62-c374-a695d0814193"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peQzWQYawUc7",
        "outputId": "8eb196fe-24c9-4343-e6c3-1a77f111fa5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use module impute to Import Simple Imputer class from sklearn to take care of the missing data.\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Use class 'SimpleImputer' to create a new object. This object will be the tool to replace the missing data with average\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
        "\n",
        "# Apply the Object 'imputer' to our matrix using fit method\n",
        "imputer.fit(x[:, 1:3])\n",
        "\n",
        "# Use transform method to apply the fit to the dataset\n",
        "x[:,1:3] = imputer.transform(x[:,1:3])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTXtsAd7exQO",
        "outputId": "4893a992-d42b-4b51-a211-7405fe92d577"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Convert categorical data into numerical data in order for the ML to understand the data.\n",
        "\n",
        "\n",
        "**1.   Label Encorder:**\n",
        "*   Encode target labels with value between 0 and n_classes-1. This transformer should be used to encode target values, i.e. y, and not the input X\n",
        "*   The problem here is, since there are different numbers in the same column, the model will misunderstand the data to be in some kind of order, 0 < 1 < 2. But this isn’t the case at all. To overcome this problem, we use One Hot Encoder.\n",
        "\n",
        "**2.   One Hot Encorder**\n",
        "*   Encode categorical features as a one-hot numeric array.\n",
        "*   The input to this transformer should be an array-like of integers or strings, denoting the values taken on by categorical (discrete) features. \n",
        "*   The features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’) encoding scheme.  \n",
        "*   This creates a binary column for each category and returns a sparse matrix or dense array (depending on the sparse parameter). \n",
        "*   By default, the encoder derives the categories based on the unique values in each feature. Alternatively, you can also specify the categories manually.\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "FBKEPKjHfegr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x))\n",
        "print(x)"
      ],
      "metadata": {
        "id": "jWMQBUMRwOiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc79a4dd-2691-4383-f1dc-ef72c34aa452"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "OtjW2UHKZ12x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975815aa-3d4f-4f8f-f7d2-6441ce317f2c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to split the dataset into the training set, which's used to train the model, and a test set, which is used to evaluate the model."
      ],
      "metadata": {
        "id": "LEsx8HsStldj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MtAVVyBVteiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using module model_selection to import train_test_split class from sklearn \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training set & testing set. Set the test size. Random_state = 1 just to make sure everyone have the same result.\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)\n",
        "print(x_train)"
      ],
      "metadata": {
        "id": "cvg2RpsOZ7ob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48681cf7-d48b-4f98-e9fd-e4baeb9a6d6a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "id": "BK-_R6xMZ_dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebc96d9-83d8-4868-903f-329716cfc274"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "id": "CYv_66pAaBET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01796bc-d605-46ed-f158-40d7ad6bad1f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "id": "L49vfN-SaA2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db99593-697e-4d1d-e4f8-59deb880d766"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply the feature scaling AFTER splitting the data set.\n",
        "\n",
        "Feature scaling consists of scaling all of the variabiles to make sure they take all values in the same scale in order to prevent one feature to dominiate the other which therefore would be neglected by the ML.\n",
        "\n",
        "*   Standardization: Work well most of the time. Value between -3 & 3\n",
        "Xstand = [x - mean(x)] / Sd(x)\n",
        "*   Normalization: Work for normal distribution. Value between 0 and 1\n",
        "Xnorm = [x - min(x)] / [max(x) - min(x)]\n",
        "\n"
      ],
      "metadata": {
        "id": "eVyqPO3NtSgJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train[:, 3:] = sc.fit_transform(x_train[:, 3:])\n",
        "x_test[:, 3:] = sc.transform(x_test[:, 3:])"
      ],
      "metadata": {
        "id": "ZF-tjF5TaEx3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "id": "Ue5JEgXeaFc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5aa9d56-eccd-4aea-c4b8-88eaffda7b58"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "id": "hlGghpoBaFP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b80b02-63e8-4041-ab81-99c607fa3d19"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ]
    }
  ]
}